{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"nlFyTg5LaIWy","executionInfo":{"status":"ok","timestamp":1704964675850,"user_tz":-420,"elapsed":5,"user":{"displayName":"Thành Đạt","userId":"12870977663865043761"}}},"outputs":[],"source":["# %%capture\n","# !pip install gdown datasets evaluate -U"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"S0GVulCzaIW1","executionInfo":{"status":"ok","timestamp":1704964675850,"user_tz":-420,"elapsed":4,"user":{"displayName":"Thành Đạt","userId":"12870977663865043761"}}},"outputs":[],"source":["# !git clone -b eval https://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@github.com/nguyenvanthanhdat/translator.git"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"yH-NomhTaIW2","executionInfo":{"status":"ok","timestamp":1704964675851,"user_tz":-420,"elapsed":5,"user":{"displayName":"Thành Đạt","userId":"12870977663865043761"}}},"outputs":[],"source":["# %cd translator"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"buParUmcaIW3","executionInfo":{"status":"ok","timestamp":1704964675851,"user_tz":-420,"elapsed":5,"user":{"displayName":"Thành Đạt","userId":"12870977663865043761"}}},"outputs":[],"source":["# !git pull"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"PAI0wxYeaIW3","executionInfo":{"status":"ok","timestamp":1704964675851,"user_tz":-420,"elapsed":5,"user":{"displayName":"Thành Đạt","userId":"12870977663865043761"}}},"outputs":[],"source":["# !ls"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eHJLFEGBaNAu","executionInfo":{"status":"ok","timestamp":1704964698820,"user_tz":-420,"elapsed":22973,"user":{"displayName":"Thành Đạt","userId":"12870977663865043761"}},"outputId":"bbd99edc-3148-4df8-a24f-4dbedf764227"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Project/translator"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dosENuqvaN9Q","executionInfo":{"status":"ok","timestamp":1704964698820,"user_tz":-420,"elapsed":6,"user":{"displayName":"Thành Đạt","userId":"12870977663865043761"}},"outputId":"8eaa65c4-864c-4afd-b977-61bfa6960ad4"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Project/translator\n"]}]},{"cell_type":"code","source":["%%capture\n","!pip install accelerate datasets evaluate peft sentencepiece -U"],"metadata":{"id":"-BadVHWnbW3w","executionInfo":{"status":"ok","timestamp":1704964710750,"user_tz":-420,"elapsed":11934,"user":{"displayName":"Thành Đạt","userId":"12870977663865043761"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["!sh scripts/eval_colab.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W59RAo9WaZDt","executionInfo":{"status":"ok","timestamp":1704964764963,"user_tz":-420,"elapsed":54218,"user":{"displayName":"Thành Đạt","userId":"12870977663865043761"}},"outputId":"7695c39b-1b69-4b64-abc4-b2f91b56779f"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["The following values were not passed to `accelerate launch` and had defaults used instead:\n","\t`--num_machines` was set to a value of `1`\n","\t`--mixed_precision` was set to a value of `'no'`\n","\t`--dynamo_backend` was set to a value of `'no'`\n","To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n","2024-01-11 09:18:49.867670: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-01-11 09:18:49.867734: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-01-11 09:18:49.870356: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-01-11 09:18:51.657881: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","******************** Load dataset ********************\n","Downloading readme: 100% 292/292 [00:00<00:00, 1.56MB/s]\n","Downloading data: 100% 4.72k/4.72k [00:00<00:00, 19.9kB/s]\n","Generating train split: 100% 10/10 [00:00<00:00, 196.43 examples/s]\n","******************** Load dataset Done ********************\n","tokenizer_config.json: 100% 82.0/82.0 [00:00<00:00, 342kB/s]\n","config.json: 100% 553/553 [00:00<00:00, 1.87MB/s]\n","spiece.model: 100% 4.31M/4.31M [00:00<00:00, 25.3MB/s]\n","special_tokens_map.json: 100% 99.0/99.0 [00:00<00:00, 429kB/s]\n","You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n","pytorch_model.bin: 100% 1.20G/1.20G [00:11<00:00, 101MB/s]\n","generation_config.json: 100% 147/147 [00:00<00:00, 648kB/s]\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n","    exec(code, run_globals)\n","  File \"/content/drive/MyDrive/Project/translator/translator/eval.py\", line 135, in <module>\n","    model = AutoModelForSeq2SeqLM.from_pretrained(args.model_name_or_path).to('cuda')\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\", line 2271, in to\n","    return super().to(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1160, in to\n","    return self._apply(convert)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 810, in _apply\n","    module._apply(fn)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 833, in _apply\n","    param_applied = fn(param)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1158, in convert\n","    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n","    torch._C._cuda_init()\n","RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/accelerate\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n","    args.func(args)\n","  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 1023, in launch_command\n","    simple_launcher(args)\n","  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 643, in simple_launcher\n","    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n","subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'translator.eval', '--model_name_or_path', 'google/mt5-small', '--tokenizer_name_or_path', 'google/mt5-small', '--hf_key', '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', '--data_test_path', 'presencesw/PhoMT_eval_10', '--split', 'train', '--num_proc', '1', '--batch_size', '1', '--max_len', '50', '--num_beams', '3,4,5', '--hf_key', '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']' returned non-zero exit status 1.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uj_ii75DaIW4"},"outputs":[],"source":["# # MODEL_NAME_OR_PATH=\"checkpoint-*\"\n","# MODEL_NAME_OR_PATH=\"google/flan-t5-large\"\n","# TOKEN_NAME='google/flan-t5-large'\n","# HF_TOKEN='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'\n","# DATA_TEST_PATH='presencesw/phomt_eval_20_256'\n","# SPLIT='test'\n","# # GDOWN_ID='1-1hVXhUpk-elUCKs6oMuxsNvIv9NFgdm' # 5K\n","# # GDOWN_ID='1RLLtLecCyoFx3yrSA5nuiWD_6qr_I0AA' # 15K\n","# GDOWN_ID='1q5wTJ6n4gpVSFM_ZVENDxSCjyyvHF2iN' # 20K\n","\n","\n","\n","\n","# !CUDA_VISIBLE_DEVICES=0,1 accelerate launch --gpu_ids 0,1 --num_processes=2 -m translator.eval \\\n","#     --model_name_or_path $MODEL_NAME_OR_PATH \\\n","#     --tokenizer_name_or_path $TOKEN_NAME \\\n","#     --hf_key $HF_TOKEN \\\n","#     --data_test_path $DATA_TEST_PATH \\\n","#     --split $SPLIT \\\n","#     --num_proc 2 \\\n","#     --batch_size 10 \\\n","#     --max_len 256 \\\n","#     --num_beams 3,4,5 \\\n","#     --hf_key $HF_TOKEN \\\n","#     --gdown_id $GDOWN_ID"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0687MAXeaIW4"},"outputs":[],"source":["# import os, datasets, evaluate\n","# os.chdir(\"eval\")\n","# bleu = evaluate.load(\"bleu\")\n","# score = open(\"../score.txt\", \"w\")\n","# for file_txt in os.listdir(\".\"):\n","#     dataset = datasets.load_dataset(\"json\", file_txt, split='train')\n","#     try:\n","#         results = bleu.compute(predictions=dataset['predict'], references=dataset['label'])\n","#     except:\n","#         results = 0\n","# score.write(f\"{file_txt}: bleu - {results}\\n\")\n","# score.close()\n","# os.chdir(\"..\")\n","# os.system(\"zip -r result.zip eval\")"]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}